SP_INSTALL-OPENWEBUI()
{
: << DOCUMENTATION

This plugin installs an OPENWEBUI instance.

Action: INSTALL-OPENWEBUI
Release: latest

# If the is already a OPENWEBUI installation, it will be removed first.
if [ "$(sudo docker ps -a -q -f name=open-webui)" ]; then
  Message "Existing OPENWEBUI installation found. Removing..."
  sudo docker stop open-webui
  sudo docker rm open-webui
fi
sudo docker stop open-webui
sudo docker rm open-webui


sudo docker run -d -p 3000:8080 \
  --gpus=all \
  -v ollama:/root/.ollama \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:ollama

# Then import Large Language Models:
lst_LLM="phi3:mini mistral:latest codellama:latest llama3:latest llama3.1:latest"
for llm in $lst_LLM; do
  docker exec -it open-webui ollama pull $llm
done
docker exec -it open-webui ollama list

# Finally create an OPE


# Then import models:


docker exec -it open-webui ollama pull phi3:mini
docker exec -it open-webui ollama pull mistral

  docker pull ollama/ollama:$RELEASE
  docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
  docker run -d -p 8080:8080 --name open-webui   -e OLLAMA_BASE_URL=http://127.0.0.1:11434   -e WEBUI_SECRET_KEY=devkey123   ghcr.io/open-webui/open-webui:ollama
  docker exec -it open-webui bash -c "apt update && apt install -y net-tools && netstat -tulpn"

NOTES:
    curl -fsSL https://ollama.com/install.sh | sh
    ollama serve
    ollama pull llama3.1:latest
    ollama list
    ollama run llama3.1:latest

ollama list
NAME                ID              SIZE      MODIFIED
phi:latest          e2fd6321a5fe    1.6 GB    6 weeks ago
mistral:latest      6577803aa9a0    4.4 GB    6 weeks ago
codellama:latest    8fdf8f752f6e    3.8 GB    6 weeks ago
llama3:latest       365c0bd3c000    4.7 GB    6 weeks ago
llama3.1:latest     46e0c10c039e    4.9 GB    2 months ago

########
sudo apt update && sudo apt upgrade -y
sudo apt install -y docker.io
sudo systemctl enable --now docker
sudo docker run -d -p 3000:8080 \
  -v ollama:/root/.ollama \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:ollama
echo "Open WebUI with Ollama backend has been set up and is running on port 3000."

sudo docker exec -it open-webui ollama pull codellama:7b
echo "Codellama 7B model has been pulled into Ollama."
sudo docker exec -it open-webui ollama pull codellama:13b

cat <<EOF > Modelfile
FROM codellama:7b
SYSTEM "You are a helpful assistant specialising in Bash and Python coding. Always provide clean, working examples."
EOF

sudo docker exec -it open-webui ollama build -t codellama-bash-helper:1.0 Modelfile
echo "Custom model 'codellama-bash-helper:1.0' has been built."

sudo docker exec -it open-webui ollama run codellama-bash-helper:1.0
echo "Custom model 'codellama-bash-helper:1.0' is ready to use."


DOCUMENTATION

  GetVar -pattern "release" -name "RELEASE" -default "latest" # Task will pause for (x) seconds

  Message "Install Ollama $RELEASE"

}